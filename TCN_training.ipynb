{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNZZZWcGs4JIy9VFqPxcMID",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MANUPRIYASINGH/MSWC_FSCIL_Reproduction/blob/main/TCN_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "icjzGLfVhEx5",
        "outputId": "c2dc6223-ca17-4560-d6eb-6de14e4f000f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting neurobench\n",
            "  Downloading neurobench-1.0.5-py3-none-any.whl (52 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.4/52.4 kB\u001b[0m \u001b[31m745.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting llvmlite<0.41.0,>=0.40.1 (from neurobench)\n",
            "  Downloading llvmlite-0.40.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (42.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.1/42.1 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting numba<0.58.0,>=0.57.1 (from neurobench)\n",
            "  Downloading numba-0.57.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from neurobench) (1.25.2)\n",
            "Collecting snntorch<0.8.0,>=0.7.0 (from neurobench)\n",
            "  Downloading snntorch-0.7.0-py2.py3-none-any.whl (108 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.0/109.0 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tonic<2.0.0,>=1.4.0 (from neurobench)\n",
            "  Downloading tonic-1.4.3-py3-none-any.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.7/110.7 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch<3.0.0,>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from neurobench) (2.3.0+cu121)\n",
            "Requirement already satisfied: torchaudio<3.0.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from neurobench) (2.3.0+cu121)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from neurobench) (4.66.4)\n",
            "Collecting numpy<2.0.0,>=1.24.3 (from neurobench)\n",
            "  Downloading numpy-1.24.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m35.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from snntorch<0.8.0,>=0.7.0->neurobench) (2.0.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from snntorch<0.8.0,>=0.7.0->neurobench) (3.7.1)\n",
            "Collecting nir (from snntorch<0.8.0,>=0.7.0->neurobench)\n",
            "  Downloading nir-1.0.4-py3-none-any.whl (18 kB)\n",
            "Collecting nirtorch (from snntorch<0.8.0,>=0.7.0->neurobench)\n",
            "  Downloading nirtorch-1.0-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from tonic<2.0.0,>=1.4.0->neurobench) (3.9.0)\n",
            "Collecting importRosbag>=1.0.4 (from tonic<2.0.0,>=1.4.0->neurobench)\n",
            "  Downloading importRosbag-1.0.4-py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from tonic<2.0.0,>=1.4.0->neurobench) (1.11.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from tonic<2.0.0,>=1.4.0->neurobench) (4.12.2)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.10/dist-packages (from tonic<2.0.0,>=1.4.0->neurobench) (0.10.2.post1)\n",
            "Collecting pbr (from tonic<2.0.0,>=1.4.0->neurobench)\n",
            "  Downloading pbr-6.0.0-py2.py3-none-any.whl (107 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.5/107.5 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting expelliarmus (from tonic<2.0.0,>=1.4.0->neurobench)\n",
            "  Downloading expelliarmus-1.1.12-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.0.1->neurobench) (3.15.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.0.1->neurobench) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.0.1->neurobench) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.0.1->neurobench) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.0.1->neurobench) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch<3.0.0,>=2.0.1->neurobench)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch<3.0.0,>=2.0.1->neurobench)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch<3.0.0,>=2.0.1->neurobench)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch<3.0.0,>=2.0.1->neurobench)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch<3.0.0,>=2.0.1->neurobench)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch<3.0.0,>=2.0.1->neurobench)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch<3.0.0,>=2.0.1->neurobench)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch<3.0.0,>=2.0.1->neurobench)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch<3.0.0,>=2.0.1->neurobench)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch<3.0.0,>=2.0.1->neurobench)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch<3.0.0,>=2.0.1->neurobench)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.0.1->neurobench) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch<3.0.0,>=2.0.1->neurobench)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from importRosbag>=1.0.4->tonic<2.0.0,>=1.4.0->neurobench) (67.7.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch<3.0.0,>=2.0.1->neurobench) (2.1.5)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa->tonic<2.0.0,>=1.4.0->neurobench) (3.0.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa->tonic<2.0.0,>=1.4.0->neurobench) (1.2.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa->tonic<2.0.0,>=1.4.0->neurobench) (1.4.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa->tonic<2.0.0,>=1.4.0->neurobench) (4.4.2)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from librosa->tonic<2.0.0,>=1.4.0->neurobench) (0.12.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.10/dist-packages (from librosa->tonic<2.0.0,>=1.4.0->neurobench) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa->tonic<2.0.0,>=1.4.0->neurobench) (0.3.7)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa->tonic<2.0.0,>=1.4.0->neurobench) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa->tonic<2.0.0,>=1.4.0->neurobench) (1.0.8)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->snntorch<0.8.0,>=0.7.0->neurobench) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->snntorch<0.8.0,>=0.7.0->neurobench) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->snntorch<0.8.0,>=0.7.0->neurobench) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->snntorch<0.8.0,>=0.7.0->neurobench) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->snntorch<0.8.0,>=0.7.0->neurobench) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->snntorch<0.8.0,>=0.7.0->neurobench) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->snntorch<0.8.0,>=0.7.0->neurobench) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->snntorch<0.8.0,>=0.7.0->neurobench) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->snntorch<0.8.0,>=0.7.0->neurobench) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->snntorch<0.8.0,>=0.7.0->neurobench) (2024.1)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch<3.0.0,>=2.0.1->neurobench) (1.3.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.1->librosa->tonic<2.0.0,>=1.4.0->neurobench) (4.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.1->librosa->tonic<2.0.0,>=1.4.0->neurobench) (2.31.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->snntorch<0.8.0,>=0.7.0->neurobench) (1.16.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa->tonic<2.0.0,>=1.4.0->neurobench) (3.5.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->librosa->tonic<2.0.0,>=1.4.0->neurobench) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa->tonic<2.0.0,>=1.4.0->neurobench) (2.22)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa->tonic<2.0.0,>=1.4.0->neurobench) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa->tonic<2.0.0,>=1.4.0->neurobench) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa->tonic<2.0.0,>=1.4.0->neurobench) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa->tonic<2.0.0,>=1.4.0->neurobench) (2024.6.2)\n",
            "Installing collected packages: pbr, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, llvmlite, nvidia-cusparse-cu12, nvidia-cudnn-cu12, numba, importRosbag, expelliarmus, nvidia-cusolver-cu12, nir, tonic, nirtorch, snntorch, neurobench\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.25.2\n",
            "    Uninstalling numpy-1.25.2:\n",
            "      Successfully uninstalled numpy-1.25.2\n",
            "  Attempting uninstall: llvmlite\n",
            "    Found existing installation: llvmlite 0.41.1\n",
            "    Uninstalling llvmlite-0.41.1:\n",
            "      Successfully uninstalled llvmlite-0.41.1\n",
            "  Attempting uninstall: numba\n",
            "    Found existing installation: numba 0.58.1\n",
            "    Uninstalling numba-0.58.1:\n",
            "      Successfully uninstalled numba-0.58.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pandas-stubs 2.0.3.230814 requires numpy>=1.25.0; python_version >= \"3.9\", but you have numpy 1.24.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed expelliarmus-1.1.12 importRosbag-1.0.4 llvmlite-0.40.1 neurobench-1.0.5 nir-1.0.4 nirtorch-1.0 numba-0.57.1 numpy-1.24.4 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105 pbr-6.0.0 snntorch-0.7.0 tonic-1.4.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "a772ba7806fd40de9d8bf9cae5976c8a"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install neurobench"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "import os\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, ConcatDataset\n",
        "\n",
        "from neurobench.benchmarks import Benchmark\n",
        "from neurobench.datasets import MSWC\n",
        "from neurobench.datasets.MSWC_IncrementalLoader import IncrementalFewShot\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "qc7Dn5kzhIEo"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/MANUPRIYASINGH/MSWC_FSCIL_Reproduction.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rfrf9oLcjbjL",
        "outputId": "ba07fe47-4ff7-41d0-f84c-ceb8ce666cee"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'MSWC_FSCIL_Reproduction'...\n",
            "remote: Enumerating objects: 32, done.\u001b[K\n",
            "remote: Counting objects: 100% (32/32), done.\u001b[K\n",
            "remote: Compressing objects: 100% (28/28), done.\u001b[K\n",
            "remote: Total 32 (delta 8), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (32/32), 17.86 MiB | 13.67 MiB/s, done.\n",
            "Resolving deltas: 100% (8/8), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd MSWC_FSCIL_Reproduction/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lIccJbjqtEUv",
        "outputId": "66c97aa7-9398-4f8a-a666-6c2127cc91b9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/MSWC_FSCIL_Reproduction\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/V0XNIHILI/TCN-library.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-qcIJmnjgAZ",
        "outputId": "1a9e2880-c0b1-40d7-c1fd-2e22e26bacc2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/V0XNIHILI/TCN-library.git\n",
            "  Cloning https://github.com/V0XNIHILI/TCN-library.git to /tmp/pip-req-build-32fuoqpx\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/V0XNIHILI/TCN-library.git /tmp/pip-req-build-32fuoqpx\n",
            "  Resolved https://github.com/V0XNIHILI/TCN-library.git to commit a32c26e70cff873fb397871f7697ec56cc8d5116\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from tcn-library==0.0.1) (2.3.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->tcn-library==0.0.1) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->tcn-library==0.0.1) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->tcn-library==0.0.1) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->tcn-library==0.0.1) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->tcn-library==0.0.1) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->tcn-library==0.0.1) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->tcn-library==0.0.1) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->tcn-library==0.0.1) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->tcn-library==0.0.1) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->tcn-library==0.0.1) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->tcn-library==0.0.1) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->tcn-library==0.0.1) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->tcn-library==0.0.1) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->tcn-library==0.0.1) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->tcn-library==0.0.1) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch->tcn-library==0.0.1) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->tcn-library==0.0.1) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch->tcn-library==0.0.1) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->tcn-library==0.0.1) (12.5.82)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->tcn-library==0.0.1) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->tcn-library==0.0.1) (1.3.0)\n",
            "Building wheels for collected packages: tcn-library\n",
            "  Building wheel for tcn-library (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tcn-library: filename=tcn_library-0.0.1-py3-none-any.whl size=12922 sha256=273cd95894c974a40a98a63a2d7b9065592c5c91108a68180cd64a98b0ba9e54\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-7_53ltlo/wheels/0c/56/1c/31842b9b5052d6df41c630521df68b0b12ddf10a0214d6766e\n",
            "Successfully built tcn-library\n",
            "Installing collected packages: tcn-library\n",
            "Successfully installed tcn-library-0.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "QSMNgzGljiU9"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data in repo root dir\n",
        "ROOT = \"./data/\"\n",
        "\n",
        "directory = \"./model_data\"\n",
        "\n",
        "if not os.path.exists(directory):\n",
        "        try:\n",
        "            os.makedirs(directory)\n",
        "        except OSError as e:\n",
        "            if e.errno != errno.EEXIST:\n",
        "                raise\n",
        "\n",
        "NUM_WORKERS = 4\n",
        "BATCH_SIZE = 256"
      ],
      "metadata": {
        "id": "VbwF9tozlJ6B"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "if device == torch.device(\"cuda\"):\n",
        "    PIN_MEMORY = True\n",
        "else:\n",
        "    PIN_MEMORY = False\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QE8z9x4YlLv1",
        "outputId": "d5b6f103-0beb-413f-e1a4-5605a4e3d98b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SPIKING = False"
      ],
      "metadata": {
        "id": "zgbGRiWilPR0"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from neurobench.preprocessing import MFCCPreProcessor, S2SPreProcessor\n",
        "\n",
        "n_fft = 512\n",
        "win_length = None\n",
        "hop_length = 240\n",
        "n_mels = 20\n",
        "n_mfcc = 20\n",
        "\n",
        "if SPIKING:\n",
        "    encode = S2SPreProcessor(device, transpose=True)\n",
        "    config_change = {\"sample_rate\": 48000,\n",
        "                     \"hop_length\": 240}\n",
        "    encode.configure(threshold=1.0, **config_change)\n",
        "else:\n",
        "    encode = MFCCPreProcessor(\n",
        "        sample_rate=48000,\n",
        "        n_mfcc=n_mfcc,\n",
        "        melkwargs={\n",
        "            \"n_fft\": n_fft,\n",
        "            \"n_mels\": n_mels,\n",
        "            \"hop_length\": hop_length,\n",
        "            \"mel_scale\": \"htk\",\n",
        "            \"f_min\": 20,\n",
        "            \"f_max\": 4000,\n",
        "        },\n",
        "        device = device\n",
        "    )"
      ],
      "metadata": {
        "id": "twnZZiJClQ39"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_train_set = MSWC(root=ROOT, subset=\"base\", procedure=\"training\")\n",
        "\n",
        "train_loader = DataLoader(base_train_set, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY, shuffle=True)\n",
        "\n",
        "base_validation_set = MSWC(root=ROOT, subset=\"base\", procedure=\"validation\")\n",
        "\n",
        "validation_loader = DataLoader(base_validation_set, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY, shuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZHeszHXlTNq",
        "outputId": "abd89e5f-51c5-4e98-dea9-315352f0dff7"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "downloading ....\n",
            "Downloading https://huggingface.co/datasets/NeuroBench/mswc_fscil_subset/resolve/main/mswc_fscil.tar.gz\n",
            "Downloading https://cdn-lfs-us-1.huggingface.co/repos/fe/0b/fe0bb2850ccd5bea2f293f18eb86657bf4d87b81648ae0f2e225f1dfec8695e2/fb3363fd7e98f23b507f38f7059cb566eacfe8c7f4212b024513726d0d984a43?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27mswc_fscil.tar.gz%3B+filename%3D%22mswc_fscil.tar.gz%22%3B&response-content-type=application%2Fgzip&Expires=1720522910&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcyMDUyMjkxMH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmh1Z2dpbmdmYWNlLmNvL3JlcG9zL2ZlLzBiL2ZlMGJiMjg1MGNjZDViZWEyZjI5M2YxOGViODY2NTdiZjRkODdiODE2NDhhZTBmMmUyMjVmMWRmZWM4Njk1ZTIvZmIzMzYzZmQ3ZTk4ZjIzYjUwN2YzOGY3MDU5Y2I1NjZlYWNmZThjN2Y0MjEyYjAyNDUxMzcyNmQwZDk4NGE0Mz9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSomcmVzcG9uc2UtY29udGVudC10eXBlPSoifV19&Signature=t7twDyZxafOojMrxwP9l13WjZnf32ZZSm8N3qaYXijq2mKJmBYLkPoUp%7EhKyoc-t%7EFc5nxET9tJ7s7Z3-V4bKsA1-XEuQCvRjeKXlYDaMqV0DOz%7E0FKVPvlcMsMXecg-xJApeIn7cyyPKmRynm5TXR0cwhhbOIf8T3tpLKdfKJyMPNC1QJgfIi39z9fd3ugx8COBQwZBmW9RpM6EXS5uLRWwKEVLEUWXaxp%7EB8S2mlCeRA%7EbqSLsMc2jLUmHr7KTLwZyuSJrU7f-cGWebAUm7SUesKG32nwiX3L7tjgcdVZL5gSgF-vM4KpYWvpWSgVjZZ%7E8-eKURXgFlaXeCZXUOQ__&Key-Pair-Id=K24J24Z295AEI9 to ./data/mswc_fscil.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 651349274/651349274 [00:03<00:00, 204118146.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unzipping file...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting files: 100%|██████████| 90244/90244 [00:27<00:00, 3329.06file/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tcn_lib import TCN\n",
        "from torchsummary import summary\n",
        "\n",
        "feature_count = 128\n",
        "model = TCN(20, 200, [64] * 2 + [128] * 2, [9] * 4, batch_norm=True, weight_norm=True,\n",
        "            residual=True, bottleneck=True, groups=32, dropout = 0.2).to(device)\n",
        "\n",
        "\n",
        "summary(model, (20, 200))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eO_ZtZANlV74",
        "outputId": "f42dc596-1d09-40ea-a1cc-6fa4216daa07"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "       _WeightNorm-1                [-1, 20, 1]               0\n",
            "ParametrizedConv1d-2              [-1, 64, 200]           1,280\n",
            "       _WeightNorm-3                [-1, 20, 1]               0\n",
            "       _WeightNorm-4                [-1, 20, 1]               0\n",
            "       _WeightNorm-5                [-1, 20, 1]               0\n",
            "       _WeightNorm-6                [-1, 20, 1]               0\n",
            "       BatchNorm1d-7              [-1, 64, 200]             128\n",
            "              ReLU-8              [-1, 64, 200]               0\n",
            "           Dropout-9              [-1, 64, 200]               0\n",
            "      _WeightNorm-10                 [-1, 2, 9]               0\n",
            "ParametrizedConv1d-11              [-1, 64, 208]           1,152\n",
            "      _WeightNorm-12                 [-1, 2, 9]               0\n",
            "      _WeightNorm-13                 [-1, 2, 9]               0\n",
            "      _WeightNorm-14                 [-1, 2, 9]               0\n",
            "      _WeightNorm-15                 [-1, 2, 9]               0\n",
            "      BatchNorm1d-16              [-1, 64, 208]             128\n",
            "          Chomp1d-17              [-1, 64, 200]               0\n",
            "             ReLU-18              [-1, 64, 200]               0\n",
            "          Dropout-19              [-1, 64, 200]               0\n",
            "      _WeightNorm-20                [-1, 64, 1]               0\n",
            "ParametrizedConv1d-21              [-1, 64, 200]           4,096\n",
            "      _WeightNorm-22                [-1, 64, 1]               0\n",
            "      _WeightNorm-23                [-1, 64, 1]               0\n",
            "      _WeightNorm-24                [-1, 64, 1]               0\n",
            "      _WeightNorm-25                [-1, 64, 1]               0\n",
            "      BatchNorm1d-26              [-1, 64, 200]             128\n",
            "         Identity-27              [-1, 64, 200]               0\n",
            "          Dropout-28              [-1, 64, 200]               0\n",
            "      _WeightNorm-29                [-1, 20, 1]               0\n",
            "ParametrizedConv1d-30              [-1, 64, 200]           1,280\n",
            "      _WeightNorm-31                [-1, 20, 1]               0\n",
            "      _WeightNorm-32                [-1, 20, 1]               0\n",
            "      _WeightNorm-33                [-1, 20, 1]               0\n",
            "      _WeightNorm-34                [-1, 20, 1]               0\n",
            "      BatchNorm1d-35              [-1, 64, 200]             128\n",
            "         Identity-36              [-1, 64, 200]               0\n",
            "          Dropout-37              [-1, 64, 200]               0\n",
            "             ReLU-38              [-1, 64, 200]               0\n",
            "TemporalBottleneck-39              [-1, 64, 200]               0\n",
            "      _WeightNorm-40                [-1, 64, 1]               0\n",
            "ParametrizedConv1d-41              [-1, 64, 200]           4,096\n",
            "      _WeightNorm-42                [-1, 64, 1]               0\n",
            "      _WeightNorm-43                [-1, 64, 1]               0\n",
            "      _WeightNorm-44                [-1, 64, 1]               0\n",
            "      _WeightNorm-45                [-1, 64, 1]               0\n",
            "      BatchNorm1d-46              [-1, 64, 200]             128\n",
            "             ReLU-47              [-1, 64, 200]               0\n",
            "          Dropout-48              [-1, 64, 200]               0\n",
            "      _WeightNorm-49                 [-1, 2, 9]               0\n",
            "ParametrizedConv1d-50              [-1, 64, 216]           1,152\n",
            "      _WeightNorm-51                 [-1, 2, 9]               0\n",
            "      _WeightNorm-52                 [-1, 2, 9]               0\n",
            "      _WeightNorm-53                 [-1, 2, 9]               0\n",
            "      _WeightNorm-54                 [-1, 2, 9]               0\n",
            "      BatchNorm1d-55              [-1, 64, 216]             128\n",
            "          Chomp1d-56              [-1, 64, 200]               0\n",
            "             ReLU-57              [-1, 64, 200]               0\n",
            "          Dropout-58              [-1, 64, 200]               0\n",
            "      _WeightNorm-59                [-1, 64, 1]               0\n",
            "ParametrizedConv1d-60              [-1, 64, 200]           4,096\n",
            "      _WeightNorm-61                [-1, 64, 1]               0\n",
            "      _WeightNorm-62                [-1, 64, 1]               0\n",
            "      _WeightNorm-63                [-1, 64, 1]               0\n",
            "      _WeightNorm-64                [-1, 64, 1]               0\n",
            "      BatchNorm1d-65              [-1, 64, 200]             128\n",
            "         Identity-66              [-1, 64, 200]               0\n",
            "          Dropout-67              [-1, 64, 200]               0\n",
            "             ReLU-68              [-1, 64, 200]               0\n",
            "TemporalBottleneck-69              [-1, 64, 200]               0\n",
            "      _WeightNorm-70                [-1, 64, 1]               0\n",
            "ParametrizedConv1d-71             [-1, 128, 200]           8,192\n",
            "      _WeightNorm-72                [-1, 64, 1]               0\n",
            "      _WeightNorm-73                [-1, 64, 1]               0\n",
            "      _WeightNorm-74                [-1, 64, 1]               0\n",
            "      _WeightNorm-75                [-1, 64, 1]               0\n",
            "      BatchNorm1d-76             [-1, 128, 200]             256\n",
            "             ReLU-77             [-1, 128, 200]               0\n",
            "          Dropout-78             [-1, 128, 200]               0\n",
            "      _WeightNorm-79                 [-1, 4, 9]               0\n",
            "ParametrizedConv1d-80             [-1, 128, 232]           4,608\n",
            "      _WeightNorm-81                 [-1, 4, 9]               0\n",
            "      _WeightNorm-82                 [-1, 4, 9]               0\n",
            "      _WeightNorm-83                 [-1, 4, 9]               0\n",
            "      _WeightNorm-84                 [-1, 4, 9]               0\n",
            "      BatchNorm1d-85             [-1, 128, 232]             256\n",
            "          Chomp1d-86             [-1, 128, 200]               0\n",
            "             ReLU-87             [-1, 128, 200]               0\n",
            "          Dropout-88             [-1, 128, 200]               0\n",
            "      _WeightNorm-89               [-1, 128, 1]               0\n",
            "ParametrizedConv1d-90             [-1, 128, 200]          16,384\n",
            "      _WeightNorm-91               [-1, 128, 1]               0\n",
            "      _WeightNorm-92               [-1, 128, 1]               0\n",
            "      _WeightNorm-93               [-1, 128, 1]               0\n",
            "      _WeightNorm-94               [-1, 128, 1]               0\n",
            "      BatchNorm1d-95             [-1, 128, 200]             256\n",
            "         Identity-96             [-1, 128, 200]               0\n",
            "          Dropout-97             [-1, 128, 200]               0\n",
            "      _WeightNorm-98                [-1, 64, 1]               0\n",
            "ParametrizedConv1d-99             [-1, 128, 200]           8,192\n",
            "     _WeightNorm-100                [-1, 64, 1]               0\n",
            "     _WeightNorm-101                [-1, 64, 1]               0\n",
            "     _WeightNorm-102                [-1, 64, 1]               0\n",
            "     _WeightNorm-103                [-1, 64, 1]               0\n",
            "     BatchNorm1d-104             [-1, 128, 200]             256\n",
            "        Identity-105             [-1, 128, 200]               0\n",
            "         Dropout-106             [-1, 128, 200]               0\n",
            "            ReLU-107             [-1, 128, 200]               0\n",
            "TemporalBottleneck-108             [-1, 128, 200]               0\n",
            "     _WeightNorm-109               [-1, 128, 1]               0\n",
            "ParametrizedConv1d-110             [-1, 128, 200]          16,384\n",
            "     _WeightNorm-111               [-1, 128, 1]               0\n",
            "     _WeightNorm-112               [-1, 128, 1]               0\n",
            "     _WeightNorm-113               [-1, 128, 1]               0\n",
            "     _WeightNorm-114               [-1, 128, 1]               0\n",
            "     BatchNorm1d-115             [-1, 128, 200]             256\n",
            "            ReLU-116             [-1, 128, 200]               0\n",
            "         Dropout-117             [-1, 128, 200]               0\n",
            "     _WeightNorm-118                 [-1, 4, 9]               0\n",
            "ParametrizedConv1d-119             [-1, 128, 264]           4,608\n",
            "     _WeightNorm-120                 [-1, 4, 9]               0\n",
            "     _WeightNorm-121                 [-1, 4, 9]               0\n",
            "     _WeightNorm-122                 [-1, 4, 9]               0\n",
            "     _WeightNorm-123                 [-1, 4, 9]               0\n",
            "     BatchNorm1d-124             [-1, 128, 264]             256\n",
            "         Chomp1d-125             [-1, 128, 200]               0\n",
            "            ReLU-126             [-1, 128, 200]               0\n",
            "         Dropout-127             [-1, 128, 200]               0\n",
            "     _WeightNorm-128               [-1, 128, 1]               0\n",
            "ParametrizedConv1d-129             [-1, 128, 200]          16,384\n",
            "     _WeightNorm-130               [-1, 128, 1]               0\n",
            "     _WeightNorm-131               [-1, 128, 1]               0\n",
            "     _WeightNorm-132               [-1, 128, 1]               0\n",
            "     _WeightNorm-133               [-1, 128, 1]               0\n",
            "     BatchNorm1d-134             [-1, 128, 200]             256\n",
            "        Identity-135             [-1, 128, 200]               0\n",
            "         Dropout-136             [-1, 128, 200]               0\n",
            "            ReLU-137             [-1, 128, 200]               0\n",
            "TemporalBottleneck-138             [-1, 128, 200]               0\n",
            "   LastElement1d-139                  [-1, 128]               0\n",
            "          Linear-140                  [-1, 200]          25,800\n",
            "================================================================\n",
            "Total params: 120,392\n",
            "Trainable params: 120,392\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.02\n",
            "Forward/backward pass size (MB): 10.21\n",
            "Params size (MB): 0.46\n",
            "Estimated Total Size (MB): 10.68\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SaveBestModel:\n",
        "    \"\"\"\n",
        "    Class to save the best model while training. If the current epoch's\n",
        "    validation loss is less than the previous least less, then save the\n",
        "    model state.\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self, best_valid_loss= 100\n",
        "    ):\n",
        "        self.best_valid_loss = best_valid_loss\n",
        "\n",
        "    def __call__(\n",
        "        self, current_valid_loss,\n",
        "        epoch, model\n",
        "    ):\n",
        "        if current_valid_loss < self.best_valid_loss:\n",
        "            self.best_valid_loss = current_valid_loss\n",
        "            print(f\"\\nLeast validation error: {self.best_valid_loss}\")\n",
        "            print(f\"\\nSaving best model for epoch: {epoch+1}\\n\")\n",
        "            torch.save({\n",
        "                'epoch': epoch+1,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                }, './outputs/best_model.pth')"
      ],
      "metadata": {
        "id": "xz3c_okErfN5"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Define your hyperparameters\n",
        "epochs = 15\n",
        "lr_max = 5e-3  # Initial maximum learning rate\n",
        "lr_min = 1e-5  # Minimum learning rate\n",
        "T_max = epochs  # Number of epochs for one cycle\n",
        "\n",
        "# Create loss function, optimizer, and learning rate scheduler\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr_max)\n",
        "lr_scheduler = CosineAnnealingLR(optimizer, T_max=T_max, eta_min=lr_min)\n",
        "save_best_model = SaveBestModel()\n",
        "\n",
        "for epoch in tqdm(range(epochs)):\n",
        "    train_avg_loss = 0\n",
        "    train_correct = 0\n",
        "    train_total = 0\n",
        "\n",
        "    validation_avg_loss = 0\n",
        "    validation_correct = 0\n",
        "    validation_total = 0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for data, target in train_loader:\n",
        "        data, target = encode((data.to(device), target.to(device)))\n",
        "        data = data.squeeze()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        output = model(data)  # Model returns only the output\n",
        "\n",
        "        # Calculate Loss\n",
        "        loss = criterion(output, target)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_avg_loss += loss.item()\n",
        "        _, predicted = output.max(1)\n",
        "        train_total += target.size(0)\n",
        "        train_correct += predicted.eq(target).sum().item()\n",
        "\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data, target in validation_loader:\n",
        "            data, target = encode((data.to(device), target.to(device)))\n",
        "            data = data.squeeze()\n",
        "\n",
        "            output = model(data)  # Model returns only the output\n",
        "            loss = criterion(output, target)\n",
        "\n",
        "            validation_avg_loss += loss.item()\n",
        "            _, predicted = output.max(1)\n",
        "            validation_total += target.size(0)\n",
        "            validation_correct += predicted.eq(target).sum().item()\n",
        "\n",
        "    train_loss, train_acc = train_avg_loss / len(train_loader), 100 * train_correct / train_total\n",
        "    validation_loss, validation_acc = validation_avg_loss / len(validation_loader), 100 * validation_correct / validation_total\n",
        "\n",
        "    print(f\"Epoch {epoch} - Train Loss: {train_loss:.4f} - Train Acc: {train_acc:.2f}\")\n",
        "    print(f\"Epoch {epoch} - Validation Loss: {validation_loss:.4f} - Validation Acc: {validation_acc:.2f}\")\n",
        "\n",
        "    save_best_model(\n",
        "        validation_loss, epoch, model\n",
        "    )\n",
        "\n",
        "    # Step the scheduler\n",
        "    lr_scheduler.step()\n",
        "\n",
        "print('Finished Training')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FHXoNOuctqYo",
        "outputId": "442b4912-1ffc-4e08-bfb9-d5b60c1ef8e5"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  7%|▋         | 1/15 [17:17<4:02:06, 1037.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 - Train Loss: 3.3356 - Train Acc: 17.97\n",
            "Epoch 0 - Validation Loss: 2.0011 - Validation Acc: 45.04\n",
            "\n",
            "Least validation error: 2.0011341363191604\n",
            "\n",
            "Saving best model for epoch: 1\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 13%|█▎        | 2/15 [34:45<3:46:04, 1043.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 - Train Loss: 2.0108 - Train Acc: 44.42\n",
            "Epoch 1 - Validation Loss: 1.2892 - Validation Acc: 64.26\n",
            "\n",
            "Least validation error: 1.2891912907361984\n",
            "\n",
            "Saving best model for epoch: 2\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 3/15 [52:07<3:28:35, 1042.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 - Train Loss: 1.6147 - Train Acc: 55.02\n",
            "Epoch 2 - Validation Loss: 1.0710 - Validation Acc: 69.53\n",
            "\n",
            "Least validation error: 1.070982702076435\n",
            "\n",
            "Saving best model for epoch: 3\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 27%|██▋       | 4/15 [1:09:35<3:11:36, 1045.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 - Train Loss: 1.4027 - Train Acc: 60.77\n",
            "Epoch 3 - Validation Loss: 0.9399 - Validation Acc: 73.14\n",
            "\n",
            "Least validation error: 0.9399038076400756\n",
            "\n",
            "Saving best model for epoch: 4\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 33%|███▎      | 5/15 [1:26:54<2:53:48, 1042.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 - Train Loss: 1.2678 - Train Acc: 64.20\n",
            "Epoch 4 - Validation Loss: 0.8163 - Validation Acc: 77.23\n",
            "\n",
            "Least validation error: 0.8163291275501251\n",
            "\n",
            "Saving best model for epoch: 5\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 6/15 [1:44:11<2:36:06, 1040.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 - Train Loss: 1.1637 - Train Acc: 67.14\n",
            "Epoch 5 - Validation Loss: 0.7601 - Validation Acc: 78.71\n",
            "\n",
            "Least validation error: 0.7601367682218552\n",
            "\n",
            "Saving best model for epoch: 6\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 47%|████▋     | 7/15 [2:01:42<2:19:12, 1044.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6 - Train Loss: 1.1082 - Train Acc: 68.55\n",
            "Epoch 6 - Validation Loss: 0.7103 - Validation Acc: 79.82\n",
            "\n",
            "Least validation error: 0.7103035405278206\n",
            "\n",
            "Saving best model for epoch: 7\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 53%|█████▎    | 8/15 [2:19:16<2:02:11, 1047.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7 - Train Loss: 1.0459 - Train Acc: 70.07\n",
            "Epoch 7 - Validation Loss: 0.6739 - Validation Acc: 81.01\n",
            "\n",
            "Least validation error: 0.6738810673356056\n",
            "\n",
            "Saving best model for epoch: 8\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 9/15 [2:36:33<1:44:24, 1044.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8 - Train Loss: 0.9857 - Train Acc: 71.90\n",
            "Epoch 8 - Validation Loss: 0.6374 - Validation Acc: 81.67\n",
            "\n",
            "Least validation error: 0.6374161310493947\n",
            "\n",
            "Saving best model for epoch: 9\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 10/15 [2:53:53<1:26:54, 1042.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9 - Train Loss: 0.9516 - Train Acc: 72.78\n",
            "Epoch 9 - Validation Loss: 0.6191 - Validation Acc: 82.26\n",
            "\n",
            "Least validation error: 0.6190715804696083\n",
            "\n",
            "Saving best model for epoch: 10\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 73%|███████▎  | 11/15 [3:11:12<1:09:26, 1041.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10 - Train Loss: 0.9082 - Train Acc: 74.12\n",
            "Epoch 10 - Validation Loss: 0.6005 - Validation Acc: 83.37\n",
            "\n",
            "Least validation error: 0.600544185936451\n",
            "\n",
            "Saving best model for epoch: 11\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 12/15 [3:28:40<52:10, 1043.49s/it]  "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11 - Train Loss: 0.8906 - Train Acc: 74.48\n",
            "Epoch 11 - Validation Loss: 0.5611 - Validation Acc: 83.91\n",
            "\n",
            "Least validation error: 0.5611281864345073\n",
            "\n",
            "Saving best model for epoch: 12\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 87%|████████▋ | 13/15 [3:46:00<34:45, 1042.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12 - Train Loss: 0.8685 - Train Acc: 74.97\n",
            "Epoch 12 - Validation Loss: 0.5814 - Validation Acc: 84.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 93%|█████████▎| 14/15 [4:03:25<17:23, 1043.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13 - Train Loss: 0.8554 - Train Acc: 75.34\n",
            "Epoch 13 - Validation Loss: 0.5638 - Validation Acc: 84.35\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [4:20:50<00:00, 1043.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14 - Train Loss: 0.8455 - Train Acc: 75.76\n",
            "Epoch 14 - Validation Loss: 0.5509 - Validation Acc: 84.28\n",
            "\n",
            "Least validation error: 0.5508516222238541\n",
            "\n",
            "Saving best model for epoch: 15\n",
            "\n",
            "Finished Training\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fDbsL9JDvtfG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}